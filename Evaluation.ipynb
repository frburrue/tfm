{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pckl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/home/ubuntu/tfm/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export-augmented-check/data_train.txt\"\n",
    "output_path = \"/home/ubuntu/tfm/TrainYourOwnYOLO/Data/Source_Images/Training_Images/vott-csv-export-augmented-check/data_test.pckl\"\n",
    "mapper = {1:'Panel', 0:'Dedo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "with open(input_path) as fd:\n",
    "    for item in fd:\n",
    "        filename_and_boxes = item.rstrip('\\n').split(' ')\n",
    "        filename = filename_and_boxes[0]\n",
    "        boxes = filename_and_boxes[1:]\n",
    "        d = {'filename': filename, 'object':[]}\n",
    "        for box in boxes:\n",
    "            box = box.split(',')\n",
    "            d['object'].append({'xmin':int(box[0]), 'ymin':int(box[1]), 'xmax': int(box[2]), 'ymax': int(box[3]), 'name': mapper[int(box[4])]})\n",
    "        rows.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pckl.dump(rows, open(output_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import pickle as pckl\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy.special import expit\n",
    "from yolo3.yolo import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, classes_path, anchors_path):\n",
    "\n",
    "    yolo = YOLO(\n",
    "        **{\n",
    "            \"model_path\": model_path,\n",
    "            \"anchors_path\": anchors_path,\n",
    "            \"classes_path\": classes_path,\n",
    "            \"score\": 0.5,\n",
    "            \"gpu_num\": 1,\n",
    "            \"model_image_size\": (416, 416),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        \n",
    "        self.c       = c\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "        \n",
    "        return self.label\n",
    "    \n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "            \n",
    "        return self.score \n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3  \n",
    "        \n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])  \n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generador de lotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator():\n",
    "    def __init__(self, instances, anchors, labels, batch_size=1, shuffle=True):\n",
    "        self.instances          = instances\n",
    "        self.batch_size         = batch_size\n",
    "        self.labels             = labels\n",
    "        self.anchors            = [BoundBox(0, 0, anchors[2*i], anchors[2*i+1]) for i in range(len(anchors)//2)]\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.instances)      \n",
    "            \n",
    "    def num_classes(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.instances)    \n",
    "\n",
    "    def get_anchors(self):\n",
    "        anchors = []\n",
    "\n",
    "        for anchor in self.anchors:\n",
    "            anchors += [anchor.xmax, anchor.ymax]\n",
    "\n",
    "        return anchors\n",
    "\n",
    "    def load_annotation(self, i):\n",
    "        annots = []\n",
    "\n",
    "        for obj in self.instances[i]['object']:\n",
    "            annot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.labels.index(obj['name'])]\n",
    "            annots += [annot]\n",
    "\n",
    "        if len(annots) == 0: annots = [[]]\n",
    "\n",
    "        return np.array(annots)\n",
    "\n",
    "    def load_image(self, i):\n",
    "        return cv2.imread(self.instances[i]['filename'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "        \n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "                    \n",
    "def get_yolo_boxes(model, images, net_h, net_w, nms_thresh):\n",
    "    batch_output, data = model.detect_image(Image.fromarray(images[0].astype('uint8')))\n",
    "    boxes = []\n",
    "    \n",
    "    for bo in batch_output:\n",
    "        b = [0]*2\n",
    "        b[bo[4]] = bo[5]\n",
    "        box = bo[:4] + [bo[5]] + [b]\n",
    "        boxes.append(BoundBox(box[0], box[1], box[2], box[3], box[4], box[5]))\n",
    "\n",
    "    # image_h, image_w, _ = images[0].shape\n",
    "    # correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
    "\n",
    "    do_nms(boxes, nms_thresh)\n",
    "    return [boxes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(model, generator, nms_thresh=0.5, net_h=416, net_w=416):  \n",
    "    # gather all detections and annotations\n",
    "    all_detections     = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
    "    all_annotations    = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
    "\n",
    "    for i in range(generator.size()):\n",
    "        raw_image = [generator.load_image(i)]\n",
    "\n",
    "        # make the boxes and the labels\n",
    "        pred_boxes = get_yolo_boxes(model, raw_image, net_h, net_w, nms_thresh)[0]\n",
    "\n",
    "        score = np.array([box.get_score() for box in pred_boxes])\n",
    "        pred_labels = np.array([box.label for box in pred_boxes])        \n",
    "        \n",
    "        if len(pred_boxes) > 0:\n",
    "            pred_boxes = np.array([[box.xmin, box.ymin, box.xmax, box.ymax, box.get_score()] for box in pred_boxes]) \n",
    "        else:\n",
    "            pred_boxes = np.array([[]])  \n",
    "        \n",
    "        # sort the boxes and the labels according to scores\n",
    "        score_sort = np.argsort(-score)\n",
    "        pred_labels = pred_labels[score_sort]\n",
    "        pred_boxes  = pred_boxes[score_sort]\n",
    "        \n",
    "        # copy detections to all_detections\n",
    "        for label in range(generator.num_classes()):\n",
    "            all_detections[i][label] = pred_boxes[pred_labels == label, :]\n",
    "\n",
    "        annotations = generator.load_annotation(i)\n",
    "        \n",
    "        # copy detections to all_annotations\n",
    "        for label in range(generator.num_classes()):\n",
    "            all_annotations[i][label] = annotations[annotations[:, 4] == label, :4].copy()\n",
    "            \n",
    "    return all_detections, all_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap(a, b):\n",
    "    \"\"\"\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a: (N, 4) ndarray of float\n",
    "    b: (K, 4) ndarray of float\n",
    "    Returns\n",
    "    -------\n",
    "    overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n",
    "    \"\"\"\n",
    "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "\n",
    "    iw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n",
    "    ih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n",
    "\n",
    "    iw = np.maximum(iw, 0)\n",
    "    ih = np.maximum(ih, 0)\n",
    "\n",
    "    ua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n",
    "\n",
    "    ua = np.maximum(ua, np.finfo(float).eps)\n",
    "\n",
    "    intersection = iw * ih\n",
    "\n",
    "    return intersection / ua  \n",
    "\n",
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(all_detections, all_annotations, generator, iou_threshold=0.5):\n",
    "    average_precisions = {}\n",
    "    \n",
    "    for label in range(generator.num_classes()):\n",
    "        false_positives = np.zeros((0,))\n",
    "        true_positives  = np.zeros((0,))\n",
    "        scores          = np.zeros((0,))\n",
    "        num_annotations = 0.0\n",
    "\n",
    "        for i in range(generator.size()):\n",
    "            detections           = all_detections[i][label]\n",
    "            annotations          = all_annotations[i][label]\n",
    "            num_annotations     += annotations.shape[0]\n",
    "            detected_annotations = []\n",
    "\n",
    "            for d in detections:\n",
    "                scores = np.append(scores, d[4])\n",
    "\n",
    "                if annotations.shape[0] == 0: # Si no hay anotaci�n de esa detecci�n es un falso positivo\n",
    "                    false_positives = np.append(false_positives, 1) # Indicador de falso positivo\n",
    "                    true_positives  = np.append(true_positives, 0) # Indicador de ausencia de falso negativo\n",
    "                    continue\n",
    "\n",
    "                overlaps            = compute_overlap(np.expand_dims(d, axis=0), annotations) # IOI\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                max_overlap         = overlaps[0, assigned_annotation]\n",
    "\n",
    "                if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives  = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives  = np.append(true_positives, 0)\n",
    "\n",
    "        # no annotations -> AP for this class is 0 (is this correct?)\n",
    "        if num_annotations == 0:\n",
    "            average_precisions[label] = 0\n",
    "            continue\n",
    "\n",
    "        # sort by score\n",
    "        indices         = np.argsort(-scores)\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives  = true_positives[indices]\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives  = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall    = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        # compute average precision\n",
    "        average_precision  = compute_ap(recall, precision)\n",
    "        average_precisions[label] = {'AP': average_precision, 'recall': recall, 'precision': precision, 'f1': f1, 'support': 0}\n",
    "\n",
    "    return average_precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de modelo y de datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/tfm/standalone/models/82f298920f8646ef89bd4313ef8202d9/artifacts/model/data/model.h5 model, anchors, and classes loaded in 14.88sec.\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/ubuntu/tfm')\n",
    "config_path = './utils/config.json'\n",
    "\n",
    "with open(config_path) as config_buffer:    \n",
    "    config = json.loads(config_buffer.read())\n",
    "\n",
    "instances = pckl.load(open(config['model']['dataset_folder'], 'rb'))\n",
    "labels = config['model']['labels']\n",
    "labels = sorted(labels)\n",
    "\n",
    "valid_generator = BatchGenerator(\n",
    "    instances           = instances,\n",
    "    anchors             = config['model']['anchors'],   \n",
    "    labels              = sorted(config['model']['labels']),\n",
    ")\n",
    "\n",
    "infer_model = load_model(config['train']['model_folder'], config['train']['classes_path'], config['train']['anchors_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "Panel 0.68 (134, 406) (333, 466)\n",
      "Time spent: 2.887sec\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "Panel 0.68 (133, 405) (334, 466)\n",
      "Time spent: 0.591sec\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "Panel 0.51 (1105, 609) (1218, 667)\n",
      "Panel 0.54 (1449, 603) (1601, 685)\n",
      "Dedo 0.89 (713, 239) (851, 591)\n",
      "Time spent: 0.564sec\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "Panel 0.53 (660, 399) (1001, 549)\n",
      "Panel 0.79 (338, 472) (563, 574)\n",
      "Time spent: 0.440sec\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "Time spent: 0.404sec\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "Panel 0.92 (576, 362) (988, 497)\n",
      "Time spent: 0.497sec\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "Panel 0.65 (179, 381) (447, 456)\n",
      "Panel 0.82 (602, 371) (1057, 466)\n",
      "Dedo 0.85 (1048, 483) (1335, 866)\n",
      "Time spent: 0.525sec\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "Dedo 0.97 (1147, 488) (1409, 956)\n",
      "Time spent: 0.544sec\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "Panel 0.61 (10, 472) (406, 634)\n",
      "Panel 0.66 (469, 310) (1109, 576)\n",
      "Dedo 0.50 (1159, 425) (1530, 884)\n",
      "Time spent: 0.541sec\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "Dedo 0.97 (1120, 500) (1414, 958)\n",
      "Time spent: 0.560sec\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "Panel 0.68 (934, 390) (1298, 485)\n",
      "Panel 0.84 (1565, 483) (1777, 558)\n",
      "Dedo 0.90 (567, 474) (867, 822)\n",
      "Time spent: 0.517sec\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "Dedo 0.97 (1120, 500) (1414, 958)\n",
      "Time spent: 0.524sec\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "Panel 0.86 (584, 300) (1070, 438)\n",
      "Dedo 0.97 (1079, 491) (1315, 987)\n",
      "Time spent: 0.423sec\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "Panel 0.66 (859, 292) (1386, 450)\n",
      "Panel 0.87 (1567, 222) (1910, 356)\n",
      "Dedo 0.95 (471, 536) (806, 1041)\n",
      "Time spent: 0.478sec\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "Panel 0.68 (133, 405) (334, 466)\n",
      "Time spent: 0.486sec\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "Panel 0.65 (175, 383) (448, 456)\n",
      "Panel 0.77 (605, 373) (1053, 467)\n",
      "Dedo 0.89 (1057, 476) (1339, 874)\n",
      "Time spent: 0.429sec\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "Panel 0.58 (180, 379) (439, 463)\n",
      "Panel 0.69 (616, 380) (1028, 467)\n",
      "Dedo 0.92 (1088, 520) (1382, 923)\n",
      "Time spent: 0.412sec\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "Panel 0.65 (175, 383) (448, 456)\n",
      "Panel 0.77 (605, 373) (1053, 467)\n",
      "Dedo 0.89 (1057, 476) (1339, 874)\n",
      "Time spent: 0.410sec\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "Dedo 0.84 (511, 227) (778, 604)\n",
      "Time spent: 0.421sec\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "Panel 0.58 (287, 368) (488, 427)\n",
      "Panel 0.64 (715, 404) (949, 469)\n",
      "Time spent: 0.412sec\n"
     ]
    }
   ],
   "source": [
    "all_detections, all_annotations = detection(infer_model, valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precisions = evaluation(all_detections, all_annotations, valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dedo: 0.9286\n",
      "Panel: 0.4512\n",
      "mAP: 0.6899\n"
     ]
    }
   ],
   "source": [
    "items = 0\n",
    "precision = 0\n",
    "for label, average_precision in average_precisions.items():\n",
    "    print(labels[label] + ': {:.4f}'.format(average_precision['AP']))\n",
    "    items += 1 \n",
    "    precision += average_precision['AP']\n",
    "print('mAP: {:.4f}'.format(precision / items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
